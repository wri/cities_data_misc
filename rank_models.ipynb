{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44350f74-7a1b-4b21-b314-dc21cfa7191c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3143c5ec-1966-4097-8d9d-b1e3dd20d073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import nex_gddp_utils as model_funcs\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db \n",
    "\n",
    "\n",
    "import dask_gateway\n",
    "from dask.distributed import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf01d1b-f927-4887-b464-968f1cbf7c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = sorted([\n",
    "    'UKESM1-0-LL',\n",
    "     'NorESM2-MM',\n",
    "     'NorESM2-LM',\n",
    "     'MRI-ESM2-0',\n",
    "     'MPI-ESM1-2-LR',\n",
    "     'MPI-ESM1-2-HR',\n",
    "     'MIROC6',\n",
    "     'MIROC-ES2L',\n",
    "     'KIOST-ESM',\n",
    "     'KACE-1-0-G',\n",
    "     'IPSL-CM6A-LR',\n",
    "     'INM-CM5-0',\n",
    "     'INM-CM4-8',\n",
    "     'HadGEM3-GC31-MM',\n",
    "     'HadGEM3-GC31-LL',\n",
    "     'GFDL-ESM4',\n",
    "     'GFDL-CM4',\n",
    "     'FGOALS-g3',\n",
    "     'EC-Earth3-Veg-LR',\n",
    "     'EC-Earth3',\n",
    "     'CanESM5',\n",
    "     'CNRM-ESM2-1',\n",
    "     'CNRM-CM6-1',\n",
    "     'CMCC-ESM2',\n",
    "     'CMCC-CM2-SR5',\n",
    "     'ACCESS-ESM1-5',\n",
    "     'ACCESS-CM2',\n",
    "     'TaiESM1'\n",
    "])\n",
    "models\n",
    "\n",
    "model_family = {'UKESM1-0-LL': 'HadAM',\n",
    " 'NorESM2-MM': 'CCM',\n",
    " 'NorESM2-LM': 'CCM',\n",
    " 'MRI-ESM2-0': 'UCLA GCM',\n",
    " 'MPI-ESM1-2-LR': 'ECMWF',\n",
    " 'MPI-ESM1-2-HR': 'ECMWF',\n",
    " 'MIROC6': 'MIROC',\n",
    " 'MIROC-ES2L': 'MIROC',\n",
    " 'KIOST-ESM': 'GFDL',\n",
    " 'KACE-1-0-G': 'HadAM',\n",
    " 'IPSL-CM6A-LR': 'IPSL',\n",
    " 'INM-CM5-0': 'INM',\n",
    " 'INM-CM4-8': 'INM',\n",
    " 'HadGEM3-GC31-MM': 'HadAM',\n",
    " 'HadGEM3-GC31-LL': 'HadAM',\n",
    " 'GFDL-ESM4': 'GFDL',\n",
    " 'GFDL-CM4_gr2': 'GFDL',\n",
    " 'GFDL-CM4': 'GFDL',\n",
    " 'FGOALS-g3': 'CCM',\n",
    " 'EC-Earth3-Veg-LR': 'ECMWF',\n",
    " 'EC-Earth3': 'ECMWF',\n",
    " 'CanESM5': 'CanAM',\n",
    " 'CNRM-ESM2-1': 'ECMWF',\n",
    " 'CNRM-CM6-1': 'ECMWF',\n",
    " 'CMCC-ESM2': 'CCM',\n",
    " 'CMCC-CM2-SR5': 'CCM',\n",
    " #'BCC-CSM2-MR': 'CCM',\n",
    " 'ACCESS-ESM1-5': 'HadAM',\n",
    " 'ACCESS-CM2': 'HadAM',\n",
    " 'TaiESM1': 'CCM',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b351c7-df27-4bd4-b823-9d35dff4a3b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_df = pd.read_csv(\n",
    "    # f\"s3://cities-climate-hazard/{variable}_era5.csv\",\n",
    "    f\"s3://cities-climate-hazard/CanESM5_tasmin_1980-2014.csv\",\n",
    "    storage_options={\n",
    "        \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "        \"secret\": \"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\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81708903-6140-45bb-aea3-0fd817efc769",
   "metadata": {},
   "source": [
    "See if parallelizing reading the csv is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70dda1a6-75ca-4a29-bda2-ae8b8a7d9ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gateway = dask_gateway.Gateway()\n",
    "cluster_options = gateway.cluster_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e7189a3-0e57-431d-9336-a82c5e133578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17b37dfe4cd4f619ee5790e7bf61cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Cluster Options</h2>'), GridBox(children=(HTML(value=\"<p style='font-weight: boâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options<worker_cores=1.0,\n",
      "        worker_memory=16.0,\n",
      "        image='pcccr.azurecr.io/public/planetary-computer/python:2023.6.22.0',\n",
      "        gpu=False,\n",
      "        environment={'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
      "         'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES',\n",
      "         'GDAL_HTTP_MAX_RETRY': '5',\n",
      "         'GDAL_HTTP_RETRY_DELAY': '3',\n",
      "         'USE_PYGEOS': '0'}>\n"
     ]
    }
   ],
   "source": [
    "cluster_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfe1cefa-35ac-4aa8-b8b9-ac3adb9be0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/dask_gateway/client.py:702: GatewayWarning: Adapt with `maximum=56, minimum=100` workers would exceed resource limit of 56 workers. Using `maximum=56, minimum=56` instead.\n",
      "  warnings.warn(GatewayWarning(msg[\"msg\"]))\n"
     ]
    }
   ],
   "source": [
    "cluster = gateway.new_cluster(cluster_options)\n",
    "# cluster = dask_gateway.GatewayCluster(public_address=\"https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.76e890ca286b43558f8cece0d48e0ff6/individual-scheduler-system\")\n",
    "client = cluster.get_client()\n",
    "\n",
    "cluster.adapt(minimum=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10db967e-be76-4ff5-9477-040a32fe7e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-5d3bcbc1-a688-11ee-8599-ee10cba7cb06</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_gateway.GatewayCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.a681021f56ba4f08a3244496dc513061/status\" target=\"_blank\">https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.a681021f56ba4f08a3244496dc513061/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.a681021f56ba4f08a3244496dc513061/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>GatewayCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Name: </b>prod.a681021f56ba4f08a3244496dc513061\n",
       "    <li><b>Dashboard: </b><a href='https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.a681021f56ba4f08a3244496dc513061/status' target='_blank'>https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.a681021f56ba4f08a3244496dc513061/status</a>\n",
       "  </ul>\n",
       "</div>\n",
       "\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.244.3.241:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6863a32-2f0c-4cc7-9d1b-58aca9a2184c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from distributed.diagnostics.plugin import UploadDirectory\n",
    "\n",
    "# client.register_scheduler_plugin(UploadDirectory(\"./\"))\n",
    "# client.register_worker_plugin(UploadDirectory(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51ac5c-8d9e-427f-85cc-62904525d784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_df = dd.read_csv(\n",
    "    # f\"s3://cities-climate-hazard/{variable}_era5.csv\",\n",
    "    f\"s3://cities-climate-hazard/CanESM5_tasmin_1980-2014.csv\",\n",
    "    storage_options={\n",
    "        \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "        \"secret\": \"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\",\n",
    "    },\n",
    "    blocksize=25e6\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d817d-afc3-4484-a653-21fc145bbbc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Yup a lot faster (3x on 50 worker 1vcpu-8G cluster) to read the csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c09379-3ad7-4484-b70f-453b5ed388e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_df.index = pd.date_range(start='1980-01-01', end='2014-12-31', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628bdf4-ac75-4f93-9a73-5758074ed015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_df = model_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce3846-7c37-4208-bb61-a02c3f658e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ds = xr.Dataset(\n",
    "    {'min_temp': (['model', 'time', 'city'], [model_df.head(), model_df.head() * .9])},\n",
    "    coords={'model': ['CanESM5', 'foo'], 'time': model_df.head().index, 'city': model_df.head().columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "470fde19-63c1-4c38-8038-cbed707f10eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_df = pd.read_csv('../era5/air_temperature_at_2_metres.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198699cd-4174-4aa4-8729-fadfc92f016f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f627e2-e280-470e-aa29-354ec3233674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rmsd = model_df.aggregate(model_funcs.get_rmsd, d2=obs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "153efde3-1b5f-41bd-8efd-8ae80fc843fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 20:23:47,523 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "variable_mapping = {\n",
    "    'tasmin': 'air_temperature_at_2_metres_1hour_Minimum',\n",
    "    'tasmax': 'air_temperature_at_2_metres_1hour_Maximum',\n",
    "    'tas': 'air_temperature_at_2_metres',\n",
    "    'pr': 'precipitation_amount_1hour_Accumulation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2127a843-9844-4dc5-8440-775b2af72222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rank_model(model, variable):\n",
    "\n",
    "    obs_ddf = dd.read_parquet(\n",
    "        f's3://cities-climate-hazard/{variable_mapping[variable]}.parquet',\n",
    "        storage_options={\n",
    "            \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "            \"secret\": \"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\",\n",
    "            },\n",
    "        blocksize=25e6\n",
    "    )\n",
    "    obs_df = obs_ddf.compute()\n",
    "\n",
    "    model_ddf = dd.read_parquet(\n",
    "        f\"s3://cities-climate-hazard/{model}_{variable}_1980-2014.parquet\",\n",
    "        storage_options={\n",
    "            \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "            \"secret\": \"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\",\n",
    "            },\n",
    "        blocksize=25e6\n",
    "    )\n",
    "    model_df = model_ddf.compute()\n",
    "    # model_ddf = dd.read_csv(\n",
    "    #     f\"s3://cities-climate-hazard/{model}_{variable}_1980-2014.csv\",\n",
    "    #     storage_options={\n",
    "    #         \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "    #         \"secret\": \"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\",\n",
    "    #         },\n",
    "    #     blocksize=25e6\n",
    "    # )  \n",
    "    \n",
    "    rprint(model_df.shape, model)\n",
    "    model_df.index = pd.date_range(start='1980-01-01', end='2014-12-31', freq='D')\n",
    "    \n",
    "    # model_ddf.to_parquet(\n",
    "    #     f\"s3://cities-climate-hazard/{model}_{variable}_1980-2014.parquet\",\n",
    "    #     storage_options={\n",
    "    #         \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "    #         \"secret\": \"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\",\n",
    "    #         },\n",
    "    #     overwrite=True\n",
    "    # )\n",
    "    \n",
    "    return model_df.aggregate(get_rmsd, d2=obs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "604c9c90-dc42-4e97-beea-1c86d0ae23f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_bag = db.from_sequence(\n",
    "    models,\n",
    "    # ['MIROC6'],\n",
    "    npartitions=56  # Number of partitions should match the number of workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ee61c49-a1e8-4c19-8e03-0561602841f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12784, 13135) EC-Earth3-Veg-LR\n",
      "(12784, 13135) EC-Earth3\n",
      "(12784, 13135) KIOST-ESM\n",
      "(12784, 13135) CanESM5\n",
      "(12784, 13135) CMCC-ESM2\n",
      "(12784, 13135) INM-CM5-0\n",
      "(12784, 13135) GFDL-ESM4\n",
      "(12784, 13135) MIROC6\n",
      "(12784, 13135) ACCESS-CM2\n",
      "(12784, 13135) FGOALS-g3\n",
      "(12784, 13135) MIROC-ES2L\n",
      "(12784, 13135) CMCC-CM2-SR5\n",
      "(12784, 13135) ACCESS-ESM1-5\n",
      "(12784, 13135) GFDL-CM4\n",
      "(12784, 13135) HadGEM3-GC31-LL\n",
      "(12784, 13135) MRI-ESM2-0\n",
      "(12784, 13135) TaiESM1\n",
      "(12784, 13135) NorESM2-LM\n",
      "(12784, 13135) MPI-ESM1-2-HR\n",
      "(12784, 13135) NorESM2-MM\n",
      "(12784, 13135) KACE-1-0-G\n",
      "(12784, 13135) UKESM1-0-LL\n",
      "(12784, 13135) CNRM-ESM2-1\n",
      "(12784, 13135) CNRM-CM6-1\n",
      "(12784, 13135) MPI-ESM1-2-LR\n",
      "(12784, 13135) INM-CM4-8\n",
      "(12784, 13135) HadGEM3-GC31-MM\n",
      "(12784, 13135) IPSL-CM6A-LR\n"
     ]
    }
   ],
   "source": [
    "rmsd = models_bag.map(rank_model, 'pr').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74f58ad2-69d1-4429-bff2-7f807d269a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmsd_df = pd.DataFrame(rmsd, index=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82f254-77b8-4a2a-beff-020756c69d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmsd_df['KEN_Nairobi'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24a0259a-2340-49c4-9ddc-a1f7444a5dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmsd_df.to_csv('./rmsd_pr.csv', index_label='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739d98f-948a-44e1-a484-fff6f80114b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8f5b458-b7e5-4ee5-a35f-fb301bf8c740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.date(2023,12,30) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219f68a-7f2e-467d-b8b9-f9629e697f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_df = pd.read_csv(f'../era5/air_temperature_at_2_metres_1hour_Maximum.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4dea4c6-9899-48fd-86b8-8d2d89e84a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_df.to_parquet(\n",
    "    f\"s3://cities-climate-hazard/air_temperature_at_2_metres.parquet\",\n",
    "    storage_options={\n",
    "        \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "        \"secret\": \"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\",\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a63f03-484a-45a8-9cbc-65b5be681292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ddf = dd.read_parquet(\n",
    "    f\"s3://cities-climate-hazard/{model}_{variable}_1980-2014.parquet\",\n",
    "    storage_options={\n",
    "        \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "        \"secret\": \"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\",\n",
    "        },\n",
    "    blocksize=25e6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ae40d7-9560-4d78-9134-cb4429237c6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "HIST_START = 1980\n",
    "HIST_END = 2014\n",
    "\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "PERCENTILE_STARTYEAR = 1980\n",
    "PERCENTILE_ENDYEAR = 2019\n",
    "\n",
    "def calendardate_percentiles(nex_varname, q, latlon, sh_hem=False):\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(hist_start, hist_end):\n",
    "        allyears.append(get_observed_gee(nex_varname, latlon, start_year=year, end_year=year, southern_hem=False))\n",
    "    if not sh_hem:\n",
    "        return np.percentile(np.vstack(allyears), q, axis=0)\n",
    "    else:\n",
    "        res = np.percentile(np.vstack(allyears), q, axis=0)\n",
    "        return np.concatenate([res[152:], res[:152]])\n",
    "\n",
    "def wholeyear_percentile(nex_varname, q, latlon):\n",
    "    if not nex_varname == 'ari':\n",
    "        hist_start = PERCENTILE_STARTYEAR\n",
    "        hist_end = PERCENTILE_ENDYEAR\n",
    "        allyears = []\n",
    "        for year in range(hist_start, hist_end):\n",
    "            allyears.append(get_observed_gee(nex_varname, latlon, start_year=year, end_year=year, southern_hem=False))\n",
    "        return np.percentile(np.concatenate(allyears).flatten(), q)\n",
    "    else:\n",
    "        hist_start = PERCENTILE_STARTYEAR\n",
    "        hist_end = PERCENTILE_ENDYEAR\n",
    "        allyears = []\n",
    "        for year in range(hist_start, hist_end):\n",
    "            allyears.append(get_observed_gee('pr', latlon, start_year=year, end_year=year, southern_hem=False))\n",
    "        ari_data = ari(np.concatenate(allyears).flatten())\n",
    "        return np.percentile(ari_data, 95)\n",
    "\n",
    "def yearextreme_percentile(nex_varname, q, latlon, wantmax):\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(hist_start, hist_end):\n",
    "        allyears.append(get_observed_gee(nex_varname, latlon, start_year=year, end_year=year, southern_hem=False))\n",
    "    return np.percentile(np.array(allyears), q)\n",
    "\n",
    "def d2j(datestring):\n",
    "    d = datetime.date.fromisoformat(datestring)\n",
    "    jday = d.timetuple().tm_yday\n",
    "    if calendar.isleap(d.year) and jday > 59:\n",
    "        jday -= 1\n",
    "    return jday\n",
    "\n",
    "def removeLeapDays(arr, start_year, end_year, southern_hem):\n",
    "    indices_to_remove = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        if calendar.isleap(year):\n",
    "            indices_to_remove.append(((year-start_year) * 365) + [0,183][int(southern_hem)] + len(indices_to_remove) + 59)\n",
    "    return np.delete(arr, indices_to_remove)\n",
    "\n",
    "def get_rmsd(d1, d2):\n",
    "    c1 = seasonal_means(d1)\n",
    "    c2 = seasonal_means(d2[d1.name])\n",
    "\n",
    "    return np.sqrt(np.mean(np.sum((c1 - c2)**2)))\n",
    "\n",
    "def count_runs(tf_array, min_runsize):\n",
    "    falses = np.zeros(tf_array.shape[0]).reshape((tf_array.shape[0],1))\n",
    "    extended_a = np.concatenate([[0], tf_array, [0]])\n",
    "    df = np.diff(extended_a)\n",
    "    starts = np.nonzero(df == 1)[0]\n",
    "    ends = np.nonzero(df == -1)[0]\n",
    "    count = 0\n",
    "    for idx in range(starts.size):\n",
    "        if ends[idx] - starts[idx] >= min_runsize:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def longest_run(tf_array):\n",
    "    if np.sum(tf_array) == 0:\n",
    "        return 0\n",
    "    falses = np.zeros(tf_array.shape[0]).reshape((tf_array.shape[0],1))\n",
    "    extended_a = np.concatenate([[0], tf_array, [0]])\n",
    "    df = np.diff(extended_a)\n",
    "    starts = np.nonzero(df == 1)[0]\n",
    "    ends = np.nonzero(df == -1)[0]\n",
    "    durations = ends - starts\n",
    "    return max(durations)\n",
    "    \n",
    "def quarters(d, start_year, end_year, southern_hem=False):\n",
    "    #Takes multi-year array and returns data reorganized into quarters\n",
    "    q2 = []  # 60-151\n",
    "    q3 = []  # 152-243\n",
    "    q4 = []  # 244-334\n",
    "    q1 = []  # 335-59\n",
    "    if not southern_hem:\n",
    "        jan1_idx = 365\n",
    "        for year in range(start_year, end_year):\n",
    "            tmp = np.concatenate((d[jan1_idx - 365 : jan1_idx - 365 + 60], d[jan1_idx + 335 : jan1_idx + 365]), axis=0)\n",
    "            q1.append(tmp)\n",
    "            q2.append(d[jan1_idx + 60 : jan1_idx + 152])\n",
    "            q3.append(d[jan1_idx + 152 : jan1_idx + 244])\n",
    "            q4.append(d[jan1_idx + 244 : jan1_idx + 335])\n",
    "\n",
    "            jan1_idx += 365 + [0, 0][int(False and calendar.isleap(year))]\n",
    "        mam_res = np.vstack(q2)\n",
    "        jja_res = np.vstack(q3)\n",
    "        son_res = np.vstack(q4)\n",
    "        djf_res = np.vstack(q1)\n",
    "    else:\n",
    "        jul1_idx = 365\n",
    "        for year in range(start_year, end_year):\n",
    "            tmp = np.concatenate((d[jul1_idx - 365 : jul1_idx - 365 + 60], d[jul1_idx + 335 : jul1_idx + 365]), axis=0)\n",
    "            q3.append(tmp)\n",
    "            q4.append(d[jul1_idx + 60 : jul1_idx + 152])\n",
    "            q1.append(d[jul1_idx + 152 : jul1_idx + 244])\n",
    "            q2.append(d[jul1_idx + 244 : jul1_idx + 335])\n",
    "\n",
    "            jul1_idx += 365 + [0, 0][int(False and calendar.isleap(year))]\n",
    "        mam_res = np.vstack(q4)\n",
    "        jja_res = np.vstack(q1)\n",
    "        son_res = np.vstack(q2)\n",
    "        djf_res = np.vstack(q3)\n",
    "    return mam_res, jja_res, son_res, djf_res\n",
    "    \n",
    "def seasonal_means(d):\n",
    "    q = quarters(d, HIST_START, HIST_END)\n",
    "    return np.array([np.mean(q[0], axis=1), np.mean(q[1], axis=1), np.mean(q[2], axis=1), np.mean(q[3], axis=1)])\n",
    "\n",
    "def calibration_function(hist_obs, hist_mod):\n",
    "# Calibration functions are P-P plots of historical and modeled values\n",
    "\n",
    "    source = np.sort(hist_obs.flatten())\n",
    "    target= np.sort(hist_mod.flatten())\n",
    "   \n",
    "    if (np.max(source) == 0 and np.min(source) == 0):\n",
    "        return np.arange(0, target.size) / target.size\n",
    "    if (np.max(target) == 0 and np.min(target) == 0):\n",
    "        return np.arange(0, source.size) / source.size\n",
    "    new_indices = []\n",
    "\n",
    "    for target_idx, target_value in enumerate(target):\n",
    "        if target_idx < len(source):\n",
    "            source_value = source[target_idx]\n",
    "            if source_value > target[-1]:\n",
    "                new_indices.append(target.size - 1)\n",
    "            else:\n",
    "                new_indices.append(np.argmax(target >= source_value))\n",
    "    return np.array(new_indices) / source.size\n",
    "\n",
    "def calibrate_component(uncalibrated_data, calibration_fxn):\n",
    "    N = len(uncalibrated_data)\n",
    "    unsorted_uncalib = [(i, idx) for idx, i in enumerate(uncalibrated_data)]\n",
    "    sorted_uncalib = sorted(unsorted_uncalib)\n",
    "    result = [0] * N\n",
    "    for j in range(N):\n",
    "        X_j = j / (N + 1)\n",
    "        Y_jprime = calibration_fxn[math.floor(X_j * len(calibration_fxn))]\n",
    "        jprime = math.floor(Y_jprime * (N + 1))\n",
    "        result[sorted_uncalib[j][1]] = sorted_uncalib[min(len(sorted_uncalib)-1, jprime)][0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calibrate(uncalibrated_data, calibration_fxn):\n",
    "    mam = []\n",
    "    jja = []\n",
    "    son = []\n",
    "    djf = []\n",
    "    mam_idx = []\n",
    "    jja_idx = []\n",
    "    son_idx = []\n",
    "    djf_idx = []\n",
    "    for idx, i in enumerate(uncalibrated_data):\n",
    "        if idx % 365 >= 60 and idx % 365 < 152:\n",
    "            mam.append(uncalibrated_data[idx])\n",
    "            mam_idx.append(idx)\n",
    "        elif idx % 365 >= 152 and idx % 365 < 244:\n",
    "            jja.append(uncalibrated_data[idx])\n",
    "            jja_idx.append(idx)\n",
    "        elif idx % 365 >= 244 and idx % 365 < 335:\n",
    "            son.append(uncalibrated_data[idx])\n",
    "            son_idx.append(idx)\n",
    "        else:\n",
    "            djf.append(uncalibrated_data[idx])\n",
    "            djf_idx.append(idx)\n",
    "    \n",
    "    mam_calib = calibrate_component(np.array(mam), calibration_fxn[0])\n",
    "    jja_calib = calibrate_component(np.array(jja), calibration_fxn[1])\n",
    "    son_calib = calibrate_component(np.array(son), calibration_fxn[2])\n",
    "    djf_calib = calibrate_component(np.array(djf), calibration_fxn[3])\n",
    "    \n",
    "    result = [0] * len(uncalibrated_data)\n",
    "    for i in range(len(mam_idx)):\n",
    "        result[mam_idx[i]] = mam_calib[i]\n",
    "    for i in range(len(jja_idx)):\n",
    "        result[jja_idx[i]] = jja_calib[i]\n",
    "    for i in range(len(son_idx)):\n",
    "        result[son_idx[i]] = son_calib[i]\n",
    "    for i in range(len(djf_idx)):\n",
    "        result[djf_idx[i]] = djf_calib[i]\n",
    "\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d156207-1109-4cdd-8fad-400b3d6c6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax_rmsd = pd.read_csv('./rmsd_tasmax.csv', index_col='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73804e26-e346-4807-b5f4-bed4f3959f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasmax_rmsd['model_family'] = [model_family[idx] for idx in tasmax_rmsd.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52e5d47-9590-4b2d-b6d2-d3395f362ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IND_Kolkata</th>\n",
       "      <th>model_family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EC-Earth3-Veg-LR</th>\n",
       "      <td>19.054157</td>\n",
       "      <td>ECMWF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIROC-ES2L</th>\n",
       "      <td>19.272219</td>\n",
       "      <td>MIROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <td>19.649043</td>\n",
       "      <td>HadAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <td>20.251476</td>\n",
       "      <td>UCLA GCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSL-CM6A-LR</th>\n",
       "      <td>21.605611</td>\n",
       "      <td>IPSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <td>22.436936</td>\n",
       "      <td>CCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIOST-ESM</th>\n",
       "      <td>23.533962</td>\n",
       "      <td>GFDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CanESM5</th>\n",
       "      <td>23.556727</td>\n",
       "      <td>CanAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INM-CM5-0</th>\n",
       "      <td>24.285861</td>\n",
       "      <td>INM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  IND_Kolkata model_family\n",
       "model                                     \n",
       "EC-Earth3-Veg-LR    19.054157        ECMWF\n",
       "MIROC-ES2L          19.272219        MIROC\n",
       "ACCESS-ESM1-5       19.649043        HadAM\n",
       "MRI-ESM2-0          20.251476     UCLA GCM\n",
       "IPSL-CM6A-LR        21.605611         IPSL\n",
       "NorESM2-MM          22.436936          CCM\n",
       "KIOST-ESM           23.533962         GFDL\n",
       "CanESM5             23.556727        CanAM\n",
       "INM-CM5-0           24.285861          INM"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasmax_rmsd[['IND_Kolkata', 'model_family']].sort_values(by='IND_Kolkata').drop_duplicates(subset='model_family', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99986989-bae4-461b-8ce3-2f7b88e6738b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_df = pd.read_parquet(\n",
    "    f\"s3://cities-climate-hazard/MIROC6_pr_1980-2014.parquet\",\n",
    "    storage_options={\n",
    "        \"key\": \"AKIAUAAZPB7LT747PAX7\",\n",
    "        \"secret\": \"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\",\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746334ad-0791-489b-956e-8e76fd53e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_max = pd.read_csv('../era5/air_temperature_at_2_metres_1hour_Maximum.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf83549c-5ac5-4372-bcee-4d9ba2d3075e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "1980-01-01    299.5000\n",
       "1980-01-02    299.0625\n",
       "1980-01-03    294.8125\n",
       "1980-01-04    296.8125\n",
       "1980-01-05    296.1250\n",
       "                ...   \n",
       "2014-12-27    295.3750\n",
       "2014-12-28    295.7500\n",
       "2014-12-29    296.8750\n",
       "2014-12-30    295.6250\n",
       "2014-12-31    296.8750\n",
       "Name: IND_Kolkata, Length: 12784, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas_max['IND_Kolkata']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
