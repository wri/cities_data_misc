{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdba210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, json\n",
    "import coiled, s3fs\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import dask\n",
    "import dask.array as da\n",
    "import flox\n",
    "import xarray as xr\n",
    "xr.set_options(display_style='html')\n",
    "\n",
    "import spei\n",
    "\n",
    "import datetime, calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f44297",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST_START = 1980\n",
    "HIST_END = 2014\n",
    "\n",
    "PERCENTILE_STARTYEAR = 1980\n",
    "PERCENTILE_ENDYEAR = 2019\n",
    "\n",
    "NUM_BEST_MODELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9951f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUTURE_START, FUTURE_END = 2080, 2099\n",
    "FUTURE_SCENARIOS = ['ssp119', 'ssp126']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b29c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITYLATLON = {}\n",
    "with open('ghsl_500k.csv', 'r') as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        items = [i.strip() for i in line.split(',')]\n",
    "        CITYLATLON['city_{0}'.format(items[0])] = (float(items[2]), float(items[3]), int(items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d04f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'tasmax': ('GFDL-ESM4', 'CanESM5', 'MRI-ESM2-0', 'IPSL-CM6A-LR', 'EC-Earth3-Veg-LR'),\n",
    "    'tasmin': ('GFDL-ESM4', 'IPSL-CM6A-LR', 'CanESM5', 'MRI-ESM2-0', 'EC-Earth3-Veg-LR'),\n",
    "    'pr': ('EC-Earth3-Veg-LR'), #'GFDL-ESM4', 'IPSL-CM6A-LR', 'CanESM5', \n",
    "    'hurs': ('GFDL-ESM4', 'CanESM5', 'MRI-ESM2-0', 'IPSL-CM6A-LR', 'EC-Earth3-Veg-LR'),\n",
    "    'sfcWind': ('GFDL-ESM4', 'CanESM5', 'IPSL-CM6A-LR')\n",
    "}\n",
    "\n",
    "MODEL_URI = {}\n",
    "with open('modelinfo.csv', 'r') as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        items = [i.strip() for i in line.split(',')]\n",
    "        model, scenario, varname, the_uri = items\n",
    "        MODEL_URI[(model, scenario, varname)] = the_uri\n",
    "\n",
    "YEARLENGTH = {\n",
    "    'GFDL-ESM4': 365,\n",
    "    'CanESM5': 365,\n",
    "    'MRI-ESM2-0': 366,\n",
    "    'IPSL-CM6A-LR': 366,\n",
    "    'EC-Earth3-Veg-LR': 366\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32606e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FAMILY = {'UKESM1-0-LL': 'HadAM',\n",
    " 'NorESM2-MM': 'CCM',\n",
    " 'NorESM2-LM': 'CCM',\n",
    " 'MRI-ESM2-0': 'UCLA GCM',\n",
    " 'MPI-ESM1-2-LR': 'ECMWF',\n",
    " 'MPI-ESM1-2-HR': 'ECMWF',\n",
    " 'MIROC6': 'MIROC',\n",
    " 'MIROC-ES2L': 'MIROC',\n",
    " 'KIOST-ESM': 'GFDL',\n",
    " 'KACE-1-0-G': 'HadAM',\n",
    " 'IPSL-CM6A-LR': 'IPSL',\n",
    " 'INM-CM5-0': 'INM',\n",
    " 'INM-CM4-8': 'INM',\n",
    " 'HadGEM3-GC31-MM': 'HadAM',\n",
    " 'HadGEM3-GC31-LL': 'HadAM',\n",
    " 'GFDL-ESM4': 'GFDL',\n",
    " 'GFDL-CM4_gr2': 'GFDL',\n",
    " 'GFDL-CM4': 'GFDL',\n",
    " 'FGOALS-g3': 'CCM',\n",
    " 'EC-Earth3-Veg-LR': 'ECMWF',\n",
    " 'EC-Earth3': 'ECMWF',\n",
    " 'CanESM5': 'CanAM',\n",
    " 'CNRM-ESM2-1': 'ECMWF',\n",
    " 'CNRM-CM6-1': 'ECMWF',\n",
    " 'CMCC-ESM2': 'CCM',\n",
    " 'CMCC-CM2-SR5': 'CCM',\n",
    " 'BCC-CSM2-MR': 'CCM',\n",
    " 'ACCESS-ESM1-5': 'HadAM',\n",
    " 'ACCESS-CM2': 'HadAM',\n",
    " 'TaiESM1': 'CCM',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e61532",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = {\n",
    "    'tasmax': {\n",
    "        'era_varname': 'maximum_2m_air_temperature',\n",
    "        'nex_transform': lambda x: x - 273.5,\n",
    "        'era_transform': lambda x: x - 273.5\n",
    "    },\n",
    "    'tasmin': {\n",
    "        'era_varname': 'minimum_2m_air_temperature',\n",
    "        'nex_transform': lambda x: x - 273.5,\n",
    "        'era_transform': lambda x: x - 273.5\n",
    "    },\n",
    "\n",
    "#    'pr': {\n",
    "#        'era_varname': 'total_precipitation',\n",
    "#        'nex_transform': lambda x: x * 86400,\n",
    "#        'era_transform': lambda x: x * 1000\n",
    "#    },\n",
    "    'hurs': {\n",
    "        'era_varname': None,\n",
    "        'nex_transform': lambda x: x,\n",
    "        'era_transform': lambda x: x\n",
    "    },\n",
    "#    'sfcWind': {\n",
    "#        'era_varname': None,\n",
    "#        'nex_transform': lambda x: x * 3600 / 1000,\n",
    "#        'era_transform': lambda x: x * 3600 / 1000\n",
    "#    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e00174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALIB_FXNS = {}\n",
    "for varname in VARIABLES:\n",
    "    CALIB_FXNS[varname] = {}\n",
    "    for loc_id in [CITYLATLON[k][2] for k in list(CITYLATLON.keys())]:\n",
    "        CALIB_FXNS[varname][int(loc_id)] = {}\n",
    "for varname in VARIABLES:\n",
    "    with open('bestmodels_{0}.txt'.format(varname), 'r') as ifile:\n",
    "        for line in ifile.readlines():\n",
    "            items = [i.strip() for i in line.split('\\t')]\n",
    "            varname, model, loc_id = items[1], items[2], int(items[0])\n",
    "            CALIB_FXNS[varname][loc_id][model] = json.loads(items[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9af88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnperiod_value_daily(nex_varname, rp, latlon):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(PERCENTILE_STARTYEAR, PERCENTILE_ENDYEAR):\n",
    "        allyears.append(VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=year, end_year=year, southern_hem=False)))\n",
    "    d = np.sort(np.concatenate(allyears).flatten())\n",
    "    d = d[d > 0.01]  # Only consider actual positive events\n",
    "    vals, counts = np.unique(d, return_counts=True)\n",
    "    freqs = counts / d.size\n",
    "    cdf_y = np.cumsum(freqs)\n",
    "    targetfreq = (PERCENTILE_ENDYEAR - PERCENTILE_STARTYEAR + 1) / rp\n",
    "    return np.interp(1-targetfreq, vals, cdf_y)\n",
    "    \n",
    "\n",
    "def calendardate_percentiles(nex_varname, q, latlon, sh_hem=False):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(PERCENTILE_STARTYEAR, PERCENTILE_ENDYEAR):\n",
    "        allyears.append(VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=year, end_year=year, southern_hem=False)))\n",
    "    if not sh_hem:\n",
    "        return np.percentile(np.vstack(allyears), q, axis=0)\n",
    "    else:\n",
    "        res = np.percentile(np.vstack(allyears), q, axis=0)\n",
    "        return np.concatenate([res[152:], res[:152]])\n",
    "\n",
    "def wholeyear_percentile(nex_varname, q, latlon):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(hist_start, hist_end):\n",
    "        allyears.append(VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=year, end_year=year, southern_hem=False)))\n",
    "    return np.percentile(np.concatenate(allyears).flatten(), q)\n",
    "\n",
    "def yearextreme_percentile(nex_varname, q, latlon, wantmax):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(hist_start, hist_end):\n",
    "        allyears.append([np.min, np.max][int(wantmax)](VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=year, end_year=year, southern_hem=False))))\n",
    "    return np.percentile(np.array(allyears), q)\n",
    "\n",
    "def thresholdexceedance_mediancount(nex_varname, threshold, latlon, want_gte):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    data = VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=PERCENTILE_STARTYEAR, end_year=PERCENTILE_ENDYEAR, southern_hem=False))\n",
    "    if data.size % 365 != 0:\n",
    "        raise Exception('Data array length is not an integer multiple of 365')\n",
    "    byyear = data.reshape(data.size//365, 365)\n",
    "    if want_gte:\n",
    "        return np.median(np.sum(byyear >= threshold, axis=1))\n",
    "    else:\n",
    "        return np.median(np.sum(byyear <= threshold, axis=1))\n",
    "    \n",
    "def max_sevendaymean(arr):\n",
    "    idx_a = 0\n",
    "    idx_b = min(7, arr.size-1)\n",
    "    allmeans = []\n",
    "    while idx_b <= arr.size:\n",
    "        allmeans.append(np.mean(arr[idx_a:idx_b]))\n",
    "    return max(allmeans)\n",
    "def wholeyear_percentile(nex_varname, q, latlon):\n",
    "    era_varname = VARIABLES[nex_varname]['era_varname']\n",
    "    hist_start = PERCENTILE_STARTYEAR\n",
    "    hist_end = PERCENTILE_ENDYEAR\n",
    "    allyears = []\n",
    "    for year in range(hist_start, hist_end):\n",
    "        allyears.append(VARIABLES[nex_varname]['era_transform'](get_eravar(era_varname, latlon, start_year=year, end_year=year, southern_hem=False)))\n",
    "    return np.percentile(np.concatenate(allyears).flatten(), q)\n",
    "\n",
    "def get_rmsd(d1, d2):\n",
    "    c1 = seasonal_means(d1)\n",
    "    c2 = seasonal_means(d2)\n",
    "    return np.sqrt(np.mean(np.sum((c1 - c2)**2)))\n",
    "\n",
    "def count_runs(tf_array, min_runsize):\n",
    "    falses = np.zeros(tf_array.shape[0]).reshape((tf_array.shape[0],1))\n",
    "    extended_a = np.concatenate([[0], tf_array, [0]])\n",
    "    df = np.diff(extended_a)\n",
    "    starts = np.nonzero(df == 1)[0]\n",
    "    ends = np.nonzero(df == -1)[0]\n",
    "    count = 0\n",
    "    for idx in range(starts.size):\n",
    "        if ends[idx] - starts[idx] >= min_runsize:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def removeLeapDays(arr, start_year, end_year, southern_hem):\n",
    "    if not southern_hem:\n",
    "        indices = []\n",
    "        jan1_idx = 0\n",
    "        for year in range(start_year, end_year+1):\n",
    "            indices += [jan1_idx + i for i in range(365)]\n",
    "            jan1_idx += 365\n",
    "            if calendar.isleap(year):\n",
    "                jan1_idx += 1\n",
    "        return arr[indices]\n",
    "    else:\n",
    "        indices = []\n",
    "        jul1_idx = 0\n",
    "        for year in range(start_year-1, end_year):\n",
    "            indices += [jul1_idx + i for i in range(365)]\n",
    "            jul1_idx += 365\n",
    "            if calendar.isleap(year):\n",
    "                jul1_idx += 1\n",
    "        return arr[indices]\n",
    "\n",
    "\n",
    "def get_var(varname, model, latlon, start_year, end_year, sh_year, scenario):\n",
    "    dataset = DATASETS[(varname, model, scenario)]\n",
    "    if not sh_year:\n",
    "        dates = ('{0}-01-01'.format(start_year), '{0}-12-31'.format(end_year))\n",
    "    else:\n",
    "        dates = ('{0}-07-01'.format(start_year-1), '{0}-06-30'.format(end_year))\n",
    "    \n",
    "    ds = dataset.sel(time=slice(*dates)).sel(lat=latlon[0], lon=latlon[1], method='nearest')\n",
    "    ds = ds.values\n",
    "    if YEARLENGTH[model] == 366:\n",
    "        return removeLeapDays(ds, start_year, end_year, sh_year)\n",
    "    else:\n",
    "        return ds\n",
    "\n",
    "def quarters(d, start_year, end_year, sh_year=False):\n",
    "    q2 = []  # 60-151\n",
    "    q3 = []  # 152-243\n",
    "    q4 = []  # 244-334\n",
    "    q1 = []  # 335-59\n",
    "    if not sh_year:\n",
    "        jan1_idx = 365\n",
    "        for year in range(start_year, end_year):\n",
    "            tmp = np.concatenate((d[jan1_idx - 365 : jan1_idx - 365 + 60], d[jan1_idx + 335 : jan1_idx + 365]), axis=0)\n",
    "            q1.append(tmp)\n",
    "            q2.append(d[jan1_idx + 60 : jan1_idx + 152])\n",
    "            q3.append(d[jan1_idx + 152 : jan1_idx + 244])\n",
    "            q4.append(d[jan1_idx + 244 : jan1_idx + 335])\n",
    "\n",
    "            jan1_idx += 365 + [0, 0][int(False and calendar.isleap(year))]\n",
    "        mam_res = np.vstack(q2)\n",
    "        jja_res = np.vstack(q3)\n",
    "        son_res = np.vstack(q4)\n",
    "        djf_res = np.vstack(q1)\n",
    "    else:\n",
    "        jul1_idx = 365\n",
    "        for year in range(start_year, end_year+1):\n",
    "            tmp = np.concatenate((d[jul1_idx - 365 : jul1_idx - 365 + 60], d[jul1_idx + 335 : jul1_idx + 365]), axis=0)\n",
    "            q3.append(tmp)\n",
    "            q4.append(d[jul1_idx + 60 : jul1_idx + 152])\n",
    "            q1.append(d[jul1_idx + 152 : jul1_idx + 244])\n",
    "            q2.append(d[jul1_idx + 244 : jul1_idx + 335])\n",
    "\n",
    "            jul1_idx += 365 + [0, 0][int(False and calendar.isleap(year))]\n",
    "        mam_res = np.vstack(q4)\n",
    "        jja_res = np.vstack(q1)\n",
    "        son_res = np.vstack(q2)\n",
    "        djf_res = np.vstack(q3)\n",
    "    return mam_res, jja_res, son_res, djf_res\n",
    "    \n",
    "def seasonal_means(d):\n",
    "    q = quarters(d, HIST_START, HIST_END)\n",
    "    return np.array([np.mean(q[0], axis=1), np.mean(q[1], axis=1), np.mean(q[2], axis=1), np.mean(q[3], axis=1)])\n",
    "\n",
    "def calibration_function(hist_obs, hist_mod):\n",
    "# Calibration functions are P-P plots of historical and modeled values\n",
    "\n",
    "    source = np.sort(hist_obs.flatten())\n",
    "    target= np.sort(hist_mod.flatten())\n",
    "   \n",
    "    if (np.max(source) == 0 and np.min(source) == 0):\n",
    "        return np.arange(0, target.size) / target.size\n",
    "    if (np.max(target) == 0 and np.min(target) == 0):\n",
    "        return np.arange(0, source.size) / source.size\n",
    "    new_indices = []\n",
    "\n",
    "    for target_idx, target_value in enumerate(target):\n",
    "        if target_idx < len(source):\n",
    "            source_value = source[target_idx]\n",
    "            if source_value > target[-1]:\n",
    "                new_indices.append(target.size - 1)\n",
    "            else:\n",
    "                new_indices.append(np.argmax(target >= source_value))\n",
    "    return np.array(new_indices) / source.size\n",
    "\n",
    "def calibrate_component(uncalibrated_data, calibration_fxn):\n",
    "    N = len(uncalibrated_data)\n",
    "    unsorted_uncalib = [(i, idx) for idx, i in enumerate(uncalibrated_data)]\n",
    "    sorted_uncalib = sorted(unsorted_uncalib)\n",
    "    result = [0] * N\n",
    "    for j in range(N):\n",
    "        X_j = j / (N + 1)\n",
    "        Y_jprime = calibration_fxn[math.floor(X_j * len(calibration_fxn))]\n",
    "        jprime = math.floor(Y_jprime * (N + 1))\n",
    "        result[sorted_uncalib[j][1]] = sorted_uncalib[min(len(sorted_uncalib)-1, jprime)][0]\n",
    "    return result\n",
    "\n",
    "def calibrate(uncalibrated_data, calibration_fxn):\n",
    "    mam = []\n",
    "    jja = []\n",
    "    son = []\n",
    "    djf = []\n",
    "    mam_idx = []\n",
    "    jja_idx = []\n",
    "    son_idx = []\n",
    "    djf_idx = []\n",
    "    for idx, i in enumerate(uncalibrated_data):\n",
    "        if idx % 365 >= 60 and idx % 365 < 152:\n",
    "            mam.append(uncalibrated_data[idx])\n",
    "            mam_idx.append(idx)\n",
    "        elif idx % 365 >= 152 and idx % 365 < 244:\n",
    "            jja.append(uncalibrated_data[idx])\n",
    "            jja_idx.append(idx)\n",
    "        elif idx % 365 >= 244 and idx % 365 < 335:\n",
    "            son.append(uncalibrated_data[idx])\n",
    "            son_idx.append(idx)\n",
    "        else:\n",
    "            djf.append(uncalibrated_data[idx])\n",
    "            djf_idx.append(idx)\n",
    "    \n",
    "    mam_calib = calibrate_component(np.array(mam), calibration_fxn[0])\n",
    "    jja_calib = calibrate_component(np.array(jja), calibration_fxn[1])\n",
    "    son_calib = calibrate_component(np.array(son), calibration_fxn[2])\n",
    "    djf_calib = calibrate_component(np.array(djf), calibration_fxn[3])\n",
    "    \n",
    "    result = [0] * len(uncalibrated_data)\n",
    "    for i in range(len(mam_idx)):\n",
    "        result[mam_idx[i]] = mam_calib[i]\n",
    "    for i in range(len(jja_idx)):\n",
    "        result[jja_idx[i]] = jja_calib[i]\n",
    "    for i in range(len(son_idx)):\n",
    "        result[son_idx[i]] = son_calib[i]\n",
    "    for i in range(len(djf_idx)):\n",
    "        result[djf_idx[i]] = djf_calib[i]\n",
    "\n",
    "    return np.array(result)\n",
    "\n",
    "def get_gamma(count, size):\n",
    "    return np.random.gamma(shape = count + 0.5, size=size)\n",
    "def get_beta(count, num, size):\n",
    "    return np.random.beta(a = count + 0.5, b = num - count + 0.5, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051c870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FWICLASS:\n",
    "        # https://d1ied5g1xfgpx8.cloudfront.net/pdfs/36461.pdf\n",
    "    def __init__(self,temp,rhum,wind,prcp):\n",
    "        self.h = rhum\n",
    "        self.t = temp\n",
    "        self.w = wind\n",
    "        self.p = prcp\n",
    "    def FFMCcalc(self,ffmc0):\n",
    "        mo = (147.2*(101.0 - ffmc0))/(59.5 + ffmc0) #*Eq. 1*#\n",
    "        if (self.p > 0.5):\n",
    "            rf = self.p - 0.5 #*Eq. 2*#\n",
    "            if(mo > 150.0):\n",
    "                mo = (mo+42.5*rf*math.exp(-100.0/(251.0-mo))*\n",
    "                (1.0 - math.exp(-6.93/rf))) + (.0015*(mo - 150.0)**2)*math.sqrt(rf) #*Eq. 3b*#\n",
    "            elif mo <= 150.0:\n",
    "                mo = mo+42.5*rf*math.exp(-100.0/(251.0-mo))*(1.0 - math.exp(-6.93/rf)) #*Eq. 3a*#\n",
    "            if(mo > 250.0):\n",
    "                mo = 250.0\n",
    "        ed = .942*(self.h**.679) + (11.0*math.exp((self.h-100.0)/10.0))+0.18*(21.1-self.t) *(1.0 - 1.0/math.exp(.1150 * self.h)) #*Eq. 4*#\n",
    "        if(mo < ed):\n",
    "            ew = .618*(self.h**.753) + (10.0*math.exp((self.h-100.0)/10.0)) + .18*(21.1-self.t)*(1.0 - 1.0/math.exp(.115 * self.h)) #*Eq. 5*#\n",
    "            if(mo <= ew):\n",
    "                kl = .424*(1.0-((100.0-self.h)/100.0)**1.7)+(.0694*math.sqrt(self.w)) *(1.0 - ((100.0 - self.h)/100.0)**8) #*Eq. 7a*#\n",
    "                kw = kl * (.581 * math.exp(.0365 * self.t)) #*Eq. 7b*#\n",
    "                m = ew - (ew - mo)/10.0**kw #*Eq. 9*#\n",
    "            elif mo > ew:\n",
    "                m = mo\n",
    "        elif(mo == ed):\n",
    "            m = mo\n",
    "        elif mo > ed:\n",
    "            kl =.424*(1.0-(self.h/100.0)**1.7)+(.0694*math.sqrt(self.w))* (1.0-(self.h/100.0)**8) #*Eq. 6a*#\n",
    "            kw = kl * (.581*math.exp(.0365*self.t)) #*Eq. 6b*#\n",
    "            m = ed + (mo-ed)/10.0 ** kw #*Eq. 8*#\n",
    "        ffmc = (59.5 * (250.0 -m)) / (147.2 + m)  #*Eq. 10*#\n",
    "        if (ffmc > 101.0):\n",
    "            ffmc = 101.0\n",
    "        if (ffmc <= 0.0):\n",
    "            ffmc = 0.0\n",
    "        return ffmc\n",
    "\n",
    "    def DMCcalc(self,dmc0,mth):\n",
    "        el = [6.5,7.5,9.0,12.8,13.9,13.9,12.4,10.9,9.4,8.0,7.0,6.0]\n",
    "        t = self.t\n",
    "        if (t < -1.1):\n",
    "            t = -1.1\n",
    "        rk = 1.894*(t+1.1) * (100.0-self.h) * (el[mth-1]*0.0001) #*Eqs. 16 and 17*#\n",
    "        if self.p > 1.5:\n",
    "            ra= self.p\n",
    "            rw = 0.92*ra - 1.27  #*Eq. 11*#\n",
    "            wmi = 20.0 + 280.0/math.exp(0.023*dmc0)  #*Eq. 12*#\n",
    "            if dmc0 <= 33.0:\n",
    "                b = 100.0 /(0.5 + 0.3*dmc0)  #*Eq. 13a*#\n",
    "            elif dmc0 > 33.0:\n",
    "                if dmc0 <= 65.0:\n",
    "                    b = 14.0 - 1.3*math.log(dmc0)  #*Eq. 13b*#\n",
    "                elif dmc0 > 65.0:\n",
    "                    b = 6.2 * math.log(dmc0) - 17.2  #*Eq. 13c*#\n",
    "            wmr = wmi + (1000*rw) / (48.77+b*rw)  #*Eq. 14*#\n",
    "            pr = 43.43 * (5.6348 - math.log(wmr-20.0))  #*Eq. 15*#\n",
    "        elif self.p <= 1.5:\n",
    "            pr = dmc0\n",
    "        if (pr<0.0):\n",
    "            pr = 0.0\n",
    "        dmc = pr + rk\n",
    "        if(dmc<= 1.0):\n",
    "            dmc = 1.0\n",
    "        return dmc\n",
    "\n",
    "    def DCcalc(self,dc0,mth):\n",
    "        fl = [-1.6, -1.6, -1.6, 0.9, 3.8, 5.8, 6.4, 5.0, 2.4, 0.4, -1.6, -1.6]\n",
    "        t = self.t\n",
    "        if(t < -2.8):\n",
    "            t = -2.8\n",
    "        pe = (0.36*(t+2.8) + fl[mth-1] )/2  #*Eq. 22*#\n",
    "        if pe <=0.0:\n",
    "            pe = 0.0\n",
    "        if (self.p > 2.8):\n",
    "            ra = self.p\n",
    "            rw = 0.83*ra - 1.27 #*Eq. 18*#\n",
    "            smi = 800.0 * math.exp(-dc0/400.0) #*Eq. 19*#\n",
    "            dr = dc0 - 400.0*math.log( 1.0+((3.937*rw)/smi) ) #*Eqs. 20 and 21*#\n",
    "            if (dr > 0.0):\n",
    "                dc = dr + pe\n",
    "            else:\n",
    "                dc = pe\n",
    "        elif self.p <= 2.8:\n",
    "            dc = dc0 + pe\n",
    "        return dc\n",
    "\n",
    "    def ISIcalc(self,ffmc):\n",
    "        mo = 147.2*(101.0-ffmc) / (59.5+ffmc)  #*Eq. 1*#\n",
    "        ff = 19.115*math.exp(mo*-0.1386) * (1.0+(mo**5.31)/49300000.0)  #*Eq. 25*#\n",
    "        isi = ff * math.exp(0.05039*self.w)  #*Eq. 26*#\n",
    "        return isi\n",
    "\n",
    "    def BUIcalc(self,dmc,dc):\n",
    "        if dmc <= 0.4*dc:\n",
    "            bui = (0.8*dc*dmc) / (dmc+0.4*dc)\n",
    "        else:\n",
    "            bui = dmc-(1.0-0.8*dc/(dmc+0.4*dc))*(0.92+(0.0114*dmc)**1.7)\n",
    "        if bui <0.0:\n",
    "            bui = 0.0\n",
    "        return bui\n",
    "\n",
    "    def FWIcalc(self,isi,bui):\n",
    "        if bui <= 80.0:\n",
    "            bb = 0.1 * isi * (0.626*bui**0.809 + 2.0)  #*Eq. 28a*#\n",
    "        else:\n",
    "            bb = 0.1*isi*(1000.0/(25. + 108.64/math.exp(0.023*bui)))  #*Eq. 28b*#\n",
    "        if(bb <= 1.0):\n",
    "            fwi = bb  #*Eq. 30b*#\n",
    "        else:\n",
    "            fwi = math.exp(2.72 * (0.434*math.log(bb))**0.647)  #*Eq. 30a*#\n",
    "        return fwi\n",
    "#End of class FWI Class\n",
    "def getFWI(mth,day,temp,rhum,wind,prcp):\n",
    "    ffmc0 = 85.0\n",
    "    dmc0 = 6.0\n",
    "    dc0 = 15.0\n",
    "    rhum = np.minimum(rhum, 100.0)\n",
    "    fwisystem = FWICLASS(temp,rhum,wind,prcp)\n",
    "    ffmc = fwisystem.FFMCcalc(ffmc0)\n",
    "    dmc = fwisystem.DMCcalc(dmc0,mth)\n",
    "    dc = fwisystem.DCcalc(dc0,mth)\n",
    "    isi = fwisystem.ISIcalc(ffmc)\n",
    "    bui = fwisystem.BUIcalc(dmc,dc)\n",
    "    fwi = fwisystem.FWIcalc(isi,bui)\n",
    "    ffmc0 = ffmc\n",
    "    dmc0 = dmc\n",
    "    dc0 = dc\n",
    "\n",
    "    #return ffmc,dmc,dc,isi,bui,fwi\n",
    "    return fwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05aa86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hazard:\n",
    "    pass\n",
    "\n",
    "class FireWeather(Hazard):\n",
    "    def __init__(self, threshold):\n",
    "        self.varname = 'tasmax+pr+hurs+sfcWind'\n",
    "        self.probmodel = 'binomial'\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def count_nc(self, datalist, targetcount):\n",
    "        data_temp = datalist[0]\n",
    "        data_prcp = datalist[1]\n",
    "        data_rhum = datalist[2]\n",
    "        data_wind = datalist[3]\n",
    "        data_month = [datetime.date.fromordinal(i+1).month for i in range(365)] * (data_temp.size//365)\n",
    "        data_day = [datetime.date.fromordinal(i+1).day for i in range(365)] * (data_temp.size//365)\n",
    "        data = np.array([getFWI(data_month[idx], data_day[idx], data_temp[idx], data_rhum[idx], data_wind[idx], data_prcp[idx]) for idx in range(data_temp.size)])\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        return np.sum(np.abs(np.sum(byyear >= self.threshold, axis=1) - targetcount) < 0.5)\n",
    "\n",
    "class Tempwave_simple(Hazard):\n",
    "    def __init__(self, varname, min_duration, threshold, want_gte=True):\n",
    "        if type(threshold) == np.ndarray and threshold.size % 365 != 0:\n",
    "            raise Exception('Comparison array length is not an integer multiple of 365')\n",
    "        self.varname = varname\n",
    "        self.want_gte = want_gte\n",
    "        self.min_duration = min_duration\n",
    "        self.threshold = threshold  # May be scalar or 365-long array\n",
    "        self.probmodel = 'Poisson'\n",
    "    def count(self, datalist):\n",
    "        data = datalist[0]\n",
    "        if type(self.threshold) in (float, int, np.float64, np.int32):\n",
    "            threshold = self.threshold\n",
    "        else:   # type is np array\n",
    "            threshold = np.array([])\n",
    "            while threshold.size < data.size:\n",
    "                threshold = np.concatenate([threshold, self.threshold])\n",
    "        if self.want_gte:\n",
    "            tf_array = data >= threshold\n",
    "        else:\n",
    "            tf_array = data <= threshold\n",
    "        return count_runs(tf_array, self.min_duration)\n",
    "\n",
    "def wetbulbtemp(T, RH):\n",
    "# JA Knox et al. 2017. Two simple and accurate approximations for wet-bulb\n",
    "# temperature in moist conditions, with forecasting applications. Bull. Am.\n",
    "# Meteorol. Soc. 98(9): 1897-1906. doi:10.1175/BAMS-D-16-0246.1\n",
    "    T = T.astype(np.float64)\n",
    "    rh_percent = RH.astype(np.float64)\n",
    "    return T * np.arctan(0.151977 * np.sqrt(rh_percent + 8.313659)) + np.arctan(T + rh_percent) - np.arctan(rh_percent - 1.676331) + ((0.00391838 * ((rh_percent)**(3/2))) * np.arctan(0.023101 * rh_percent)) - 4.686035\n",
    "\n",
    "\n",
    "def wetbulbtemp_chen(T, RH):\n",
    "    return -4391976 + (0.0198197 * RH) + (0.526359 * T) + (0.00730271 * RH * T) + (0.00024315 * RH * RH) - (0.0000258101 * T * RH * RH)\n",
    "\n",
    "class WetbulbHeatwave(Hazard):\n",
    "    def __init__(self, wbgt_threshold, min_duration):\n",
    "        self.varname = 'tasmax+hurs'\n",
    "        self.min_duration = min_duration\n",
    "        self.wbgt_threshold = wbgt_threshold\n",
    "        self.probmodel = 'Poisson'\n",
    "    def count(self, datalist):\n",
    "        data_t = datalist[0]\n",
    "        data_h = datalist[1]\n",
    "        data = wetbulbtemp(data_t, data_h)\n",
    "        tf_array = data >= self.wbgt_threshold\n",
    "        return count_runs(tf_array, self.min_duration)\n",
    "\n",
    "class WetbulbDays(Hazard):\n",
    "    def __init__(self, wbgt_threshold):\n",
    "        self.varname = 'tasmax+hurs'\n",
    "        self.wbgt_threshold = wbgt_threshold\n",
    "        self.probmodel = 'binomial'\n",
    "    def count(self, datalist):\n",
    "        data_t = datalist[0]\n",
    "        data_h = datalist[1]\n",
    "        data = wetbulbtemp(data_t, data_h)\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        return np.sum((np.max(byyear, axis=1) >= self.wbgt_threshold) * 1)\n",
    "    \n",
    "    def count_nc(self, datalist, targetcount):\n",
    "        data_t = datalist[0]\n",
    "        data_h = datalist[1]\n",
    "        data = wetbulbtemp(data_t, data_h)\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        return np.sum(np.abs(np.sum(byyear >= self.wbgt_threshold, axis=1) - targetcount) < 0.5)\n",
    "    \n",
    "class Heatwave_highlow(Hazard):\n",
    "    def __init__(self, hightemp, lowtemp, min_duration):\n",
    "        self.varname = 'tasmax+tasmin'\n",
    "        self.min_duration = min_duration\n",
    "        self.hightemp = hightemp\n",
    "        self.lowtemp = lowtemp\n",
    "        self.probmodel = 'Poisson'\n",
    "    def count(self, datalist):\n",
    "        data_tx = datalist[0]\n",
    "        data_tn = datalist[1]\n",
    "        if type(self.hightemp) in (float, int, np.float64, np.int32):\n",
    "            high_threshold = self.hightemp\n",
    "        else:   # type is np array\n",
    "            high_threshold = np.array([])\n",
    "            while high_threshold.size < data_tx.size:\n",
    "                high_threshold = np.concatenate([high_threshold, self.hightemp])\n",
    "        if type(self.lowtemp) in (float, int, np.float64, np.int32):\n",
    "            low_threshold = self.lowtemp\n",
    "        else:   # type is np array\n",
    "            low_threshold = np.array([])\n",
    "            while low_threshold.size < data_tn.size:\n",
    "                low_threshold = np.concatenate([low_threshold, self.lowtemp])\n",
    "        tf_array_tx = data_tx >= high_threshold\n",
    "        tf_array_tn = data_tn >= low_threshold\n",
    "        return count_runs(tf_array_tx * tf_array_tn, self.min_duration)\n",
    "\n",
    "class Drought_SPI(Hazard):\n",
    "    def __init__(self, min_duration):\n",
    "        self.varname = 'pr'\n",
    "        self.probmodel = 'Poisson'\n",
    "        self.min_duration = min_duration\n",
    "    def count(self, datalist):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        \n",
    "        t=pd.date_range(start='1980-01-01', end='{0}-12-31'.format(1980 + (data.size//365) - 1), freq='D')\n",
    "        t = t[~((t.month == 2) & (t.day == 29))]\n",
    "        \n",
    "        tries = 0\n",
    "        success = False\n",
    "        while (not success) and tries < 5:\n",
    "            try:\n",
    "                droughtdays = spei.spi(pd.Series(data, index=t)).to_numpy()\n",
    "                success = True\n",
    "            except:\n",
    "                tries += 1\n",
    "        if success:\n",
    "            return count_runs(droughtdays < -2, self.min_duration)\n",
    "        else:\n",
    "            print(\"Returning -9999\")\n",
    "            return -9999\n",
    "    def count_nc(self, datalist, targetcount):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        \n",
    "        t=pd.date_range(start='1980-01-01', end='{0}-12-31'.format(1980 + (data.size//365) - 1), freq='D')\n",
    "        t = t[~((t.month == 2) & (t.day == 29))]\n",
    "        \n",
    "        droughtdays = spei.spi(pd.Series(data, index=t)).to_numpy()\n",
    "        byyear = droughtdays.reshape(data.size//365, 365)\n",
    "        \n",
    "        return np.sum(np.abs(np.sum(byyear <= -2, axis=1) - targetcount) < 0.5)\n",
    "    \n",
    "    \n",
    "class Threshold_simple(Hazard):\n",
    "    def __init__(self, varname, var_threshold, want_gte):\n",
    "        self.varname = varname\n",
    "        self.var_threshold = var_threshold\n",
    "        self.want_gte = want_gte\n",
    "        self.probmodel = 'binomial'\n",
    "    def count(self, datalist):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        if self.want_gte:\n",
    "            return np.sum(np.sum(byyear >= self.var_threshold, axis=1) >= self.count_threshold)\n",
    "        else:\n",
    "            return np.sum(np.sum(byyear <= self.var_threshold, axis=1) >= self.count_threshold)\n",
    "    def count_nc(self, datalist, targetcount):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        return np.sum(np.abs(np.sum(byyear >= self.var_threshold, axis=1) - targetcount) < 0.5)\n",
    "        \n",
    "\n",
    "class Hotdays_inrange(Hazard):\n",
    "    def __init__(self, hightemp, lowtemp):\n",
    "        self.varname = 'tasmax'\n",
    "        self.hightemp = hightemp\n",
    "        self.lowtemp = lowtemp\n",
    "        self.probmodel = 'binomial'\n",
    "    def count(self, datalist):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        tf_array_high = data <= self.hightemp\n",
    "        tf_array_low = data >= self.lowtemp\n",
    "        return runs(tf_array_high * tf_array_low, self.min_duration, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba21b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hazard:\n",
    "    def get_estimates(self, latlon, start_year, end_year, datasets, calib_fxns):\n",
    "        sh_year = int(latlon[0] < 0)\n",
    "        fut_mod = {}\n",
    "        varnames = self.varname.split('+')\n",
    "        for varname in varnames:\n",
    "            for model in calib_fxns[varname].keys():\n",
    "                ds = datasets[varname][model]\n",
    "\n",
    "                if YEARLENGTH[model] == 366:\n",
    "                    ds = removeLeapDays(ds, start_year, end_year, sh_year)\n",
    "                fut_mod[(varname, model)] = ds\n",
    "        best_models = []\n",
    "        for idx in range(NUM_BEST_MODELS):\n",
    "            best_models.append('+'.join([list(calib_fxns[varname].keys())[idx] for varname in varnames]))\n",
    "        res_sum = {modelplus: [0, 0, 0] for modelplus in best_models}\n",
    "        for targetval in self.targetvals:\n",
    "            for modelplus in best_models:\n",
    "                calib_data = []\n",
    "                for idx, varname in enumerate(varnames):\n",
    "                    model = modelplus.split('+')[idx]\n",
    "                    calib_data.append(np.array(calibrate(fut_mod[(varname, model)], calib_fxns[varname][model])))\n",
    "                count = self.val_nc([cd[[0,152][int(sh_year)]:[len(cd),-213][int(sh_year)]] for cd in calib_data], targetval)\n",
    "                posterior_rateparams = get_beta(count, end_year - start_year + 1, 10000)\n",
    "                if count == 0:\n",
    "                    posterior_rateparams = np.zeros(10000)\n",
    "                posterior_draws = np.random.binomial(end_year - start_year + 1, posterior_rateparams, 10000)\n",
    "                probs = [np.percentile(posterior_draws, q) / (end_year - start_year + 1) for q in (25, 50, 75)]\n",
    "                res_sum[modelplus] = [res_sum[modelplus][idx] + (targetval * probs[idx] ) for idx in (0, 1, 2)]\n",
    "        return {modelplus: [max(min(res_sum[modelplus][idx], max(self.targetvals)), 0) for idx in (0, 1, 2)] for modelplus in res_sum}\n",
    "\n",
    "class ThresholdDays(Hazard):\n",
    "    def __init__(self, hazname, varname, var_threshold, want_max, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = varname\n",
    "        self.var_threshold = var_threshold\n",
    "        self.targetvals = targetvals\n",
    "        self.want_max = want_max\n",
    "        self.probmodel = 'binomial'\n",
    "\n",
    "    def val_nc(self, datalist, targetval):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')   \n",
    "        byyear = data.reshape(data.size // 365, 365)\n",
    "        \n",
    "        if self.want_max:\n",
    "            return np.sum(np.sum(byyear <= self.var_threshold, axis=1) == targetval)\n",
    "        else:\n",
    "            return np.sum(np.sum(byyear <= self.var_threshold, axis=1) == targetval)\n",
    "    \n",
    "class WetbulbDays(Hazard):\n",
    "    def wetbulbtemp(T, RH):\n",
    "    # JA Knox et al. 2017. Two simple and accurate approximations for wet-bulb\n",
    "    # temperature in moist conditions, with forecasting applications. Bull. Am.\n",
    "    # Meteorol. Soc. 98(9): 1897-1906. doi:10.1175/BAMS-D-16-0246.1\n",
    "        T = T.astype(np.float64)\n",
    "        rh_percent = RH.astype(np.float64)\n",
    "        return T * np.arctan(0.151977 * np.sqrt(rh_percent + 8.313659)) + np.arctan(T + rh_percent) - np.arctan(rh_percent - 1.676331) + ((0.00391838 * ((rh_percent)**(3/2))) * np.arctan(0.023101 * rh_percent)) - 4.686035\n",
    "\n",
    "    def __init__(self, hazname, wbgt_threshold, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = 'tasmax+hurs'\n",
    "        self.wbgt_threshold = wbgt_threshold\n",
    "        self.probmodel = 'binomial'\n",
    "        self.targetvals = targetvals\n",
    "\n",
    "    def val_nc(self, datalist, targetcount):\n",
    "        data_t = datalist[0]\n",
    "        data_h = datalist[1]\n",
    "        data = wetbulbtemp(data_t, data_h)\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size//365, 365)\n",
    "        return np.sum(np.sum(byyear >= self.wbgt_threshold, axis=1) == targetcount)\n",
    "\n",
    "class DroughtSPIDays(Hazard):\n",
    "    def __init__(self, hazname, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = 'pr'\n",
    "        self.probmodel = 'Poisson'\n",
    "        self.targetvals = targetvals\n",
    "\n",
    "    def val_nc(self, datalist, targetcount):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        \n",
    "        t=pd.date_range(start='1980-01-01', end='{0}-12-31'.format(1980 + (data.size//365) - 1), freq='D')\n",
    "        t = t[~((t.month == 2) & (t.day == 29))]\n",
    "        \n",
    "        droughtdays = spei.spi(pd.Series(data, index=t)).to_numpy()\n",
    "        byyear = droughtdays.reshape(data.size // 365, 365)\n",
    "        \n",
    "        return np.sum(np.sum(byyear <= -2, axis=1) == targetcount)\n",
    "    \n",
    "class ExtremestVal(Hazard):\n",
    "    def __init__(self, hazname, varname, want_max, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = varname\n",
    "        self.want_max = want_max\n",
    "        self.probmodel = 'binomial'\n",
    "        self.targetvals = targetvals\n",
    "        \n",
    "    def val_nc(self, datalist, targetval):\n",
    "        data = datalist[0]\n",
    "        byyear = data.reshape(data.size // 365, 365)\n",
    "        if self.want_max:\n",
    "            return np.sum(np.round(np.max(byyear, axis=1)) == targetval)\n",
    "        else:\n",
    "            return np.sum(np.round(np.min(byyear, axis=1)) == targetval)\n",
    "    \n",
    "class RangeDays(Hazard):\n",
    "    def __init__(self, hazname, varname, low_threshold, high_threshold, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = varname\n",
    "        self.low_threshold = low_threshold\n",
    "        self.high_threshold = high_threshold\n",
    "        self.probmodel = 'binomial'\n",
    "        self.targetvals = targetvals\n",
    "        \n",
    "    def val_nc(self, datalist, targetcount):\n",
    "        data = datalist[0]\n",
    "        if data.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = data.reshape(data.size // 365, 365)\n",
    "        return np.sum(np.sum((byyear >= self.low_threshold)*(byyear <= self.high_threshold), axis=1) == targetcount)\n",
    "    \n",
    "class RangeDaysTwovar(Hazard):\n",
    "    def __init__(self, hazname, varname, low_threshold, high_threshold, targetvals):\n",
    "        self.hazname = hazname\n",
    "        self.varname = varname\n",
    "        self.low_threshold = low_threshold\n",
    "        self.high_threshold = high_threshold\n",
    "        self.probmodel = 'binomial'\n",
    "        self.targetvals = targetvals\n",
    "        \n",
    "    def val_nc(self, datalist, targetcount):\n",
    "        datalow = datalist[0]\n",
    "        datahigh = datalist[1]\n",
    "        datamid = (datalist[0] + datalist[1]) / 2\n",
    "        if datamid.size % 365 != 0:\n",
    "            raise Exception('Data array length is not an integer multiple of 365')\n",
    "        byyear = datamid.reshape(datamid.size // 365, 365)\n",
    "        return np.sum(np.sum((byyear >= self.low_threshold)*(byyear <= self.high_threshold), axis=1) == targetcount)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baea5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_URI = {}\n",
    "with open('modelinfo.csv', 'r') as ifile:\n",
    "    for line in ifile.readlines():\n",
    "        items = [i.strip() for i in line.split(',')]\n",
    "        model, scenario, varname, the_uri = items\n",
    "        MODEL_URI[(model, scenario, varname)] = the_uri\n",
    "def get_futmods_everywhere(varname, scenario, model, southern_hem):\n",
    "    def uri(model, scenario, varname):\n",
    "        return MODEL_URI[(model, scenario, varname)]\n",
    "    def s3open_cmip(path):\n",
    "        fs = s3fs.S3FileSystem(anon=True)\n",
    "        return s3fs.S3Map(path, s3=fs)\n",
    "    thefile = s3open_cmip(uri(model, scenario, varname))\n",
    "    ds = xr.open_mfdataset([thefile], engine='zarr', parallel=True)\n",
    "    if southern_hem:\n",
    "        ds = ds[varname].resample(time='D').sum().sel(time=slice('{0}-07-01'.format(FUTURE_START-1), '{0}-06-30'.format(FUTURE_END)))\n",
    "    else:\n",
    "        ds = ds[varname].resample(time='D').sum().sel(time=slice('{0}-01-01'.format(FUTURE_START), '{0}-12-31'.format(FUTURE_END)))\n",
    "    return VARIABLES[varname]['nex_transform'](ds).chunk({\"time\": -1, \"lat\": \"auto\", \"lon\": \"auto\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ead53760",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4f57d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732d8a77a6a74be1a75c333366209b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = coiled.Cluster(n_workers=50, name='cluster_1', compute_purchase_option=\"spot_with_fallback\", shutdown_on_close=False)\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4735ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ec4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_rp100 = {}\n",
    "with open('precip_rp100.txt', 'r') as ifile:\n",
    "    lines = ifile.readlines()\n",
    "    for line in lines:\n",
    "        items = line.split('\\t')\n",
    "        loc_id, val = int(items[0]), float(items[1])\n",
    "        pr_rp100[loc_id] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946cf518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(varnames, scenario, lat, lon):\n",
    "    return {varname: {model: get_futmods_everywhere(varname, scenario, model, lat < 0).sel(lat=lat, lon=lon, method='nearest').values for model in MODELS[varname]} for varname in varnames}\n",
    "\n",
    "def do_locationhazard(hazard, loc_id, latlon, scenario, calib_fxns):\n",
    "    lat, lon = latlon\n",
    "    varnames = hazard.varname.split('+')\n",
    "    datasets = getdata(varnames, scenario, lat, lon)\n",
    "    return loc_id, lat, lon, hazard.hazname, scenario, '{0}-{1}'.format(FUTURE_START, FUTURE_END), hazard.get_estimates(latlon, FUTURE_START, FUTURE_END, datasets, calib_fxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ee5ffe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:16\u001b[0m\n",
      "File \u001b[1;32m~\\halfdeg\\halfdegenv\\lib\\site-packages\\distributed\\client.py:1952\u001b[0m, in \u001b[0;36mClient.submit\u001b[1;34m(self, func, key, workers, resources, retries, priority, fifo_timeout, allow_other_workers, actor, actors, pure, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pure:\n\u001b[1;32m-> 1952\u001b[0m         key \u001b[38;5;241m=\u001b[39m funcname(func) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1953\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1954\u001b[0m         key \u001b[38;5;241m=\u001b[39m funcname(func) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n",
      "File \u001b[1;32m~\\halfdeg\\halfdegenv\\lib\\site-packages\\dask\\base.py:964\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deterministic token\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03m    >>> tokenize([1, 2, '3'])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 964\u001b[0m     hasher \u001b[38;5;241m=\u001b[39m _md5(\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnormalize_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m())\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    966\u001b[0m         hasher\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mstr\u001b[39m(normalize_token(kwargs))\u001b[38;5;241m.\u001b[39mencode())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = []\n",
    "for cityname in list(CITYLATLON.keys())[:100]:\n",
    "    lat, lon, loc_id = CITYLATLON[cityname]\n",
    "    pr_rp100_val = pr_rp100[loc_id]\n",
    "    HAZARDS = [\n",
    "        RangeDaysTwovar('numdays_tmax_betw_23.9_34', 'tasmin+tasmax', 23.9, 34, range(0, 366)),\n",
    "        ExtremestVal('max_tmax', 'tasmax', True, range(15, 60)),\n",
    "        #DroughtSPIDays('numdays_SPI_lte_-2', range(0, 366)),\n",
    "        WetbulbDays('numdays_Twb_gte_31', 31, range(0, 366)),\n",
    "        #ThresholdDays('numdays_pr_gte_rp100', 'pr', pr_rp100_val, True, range(0, 200))\n",
    "    ]\n",
    "    for hazard in HAZARDS:\n",
    "        for scenario in FUTURE_SCENARIOS:\n",
    "            varnames = hazard.varname.split('+')\n",
    "            calib_fxns = {varname: CALIB_FXNS[varname][loc_id] for varname in varnames}\n",
    "            futures.append(client.submit(do_locationhazard, hazard, loc_id, (lat, lon), scenario, calib_fxns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7198d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 406 ms\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for future in futures:\n",
    "    if future.status=='finished':\n",
    "        result = future.result()\n",
    "        with open('tempinds_996.csv', 'a') as ofile:\n",
    "            loc_id, lat, lon, hazard.hazname, scenario, year_range, valdict = result\n",
    "            for model in valdict:\n",
    "                ofile.write('{0},{1},{2},{3},{4},{5},{6},{7},{8},{9}\\n'.format(loc_id, lat, lon, hazard.hazname, scenario, model, year_range, valdict[model][0], valdict[model][1], valdict[model][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a53ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd498a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b85cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f14ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7dd43ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-CM4: min modeled value does not exceed observed 10th percentile  True\n",
      "GFDL-CM4: max modeled value does not exceed observed 90th percentile  True\n",
      "CanESM5: min modeled value does not exceed observed 10th percentile  True\n",
      "CanESM5: max modeled value does not exceed observed 90th percentile  True\n",
      "ACCESS-CM2: min modeled value does not exceed observed 10th percentile  True\n",
      "ACCESS-CM2: max modeled value does not exceed observed 90th percentile  True\n",
      "GFDL-CM4: min modeled value does not exceed observed 10th percentile  True\n",
      "GFDL-CM4: max modeled value does not exceed observed 90th percentile  True\n",
      "CanESM5: min modeled value does not exceed observed 10th percentile  True\n",
      "CanESM5: max modeled value does not exceed observed 90th percentile  True\n",
      "ACCESS-CM2: min modeled value does not exceed observed 10th percentile  True\n",
      "ACCESS-CM2: max modeled value does not exceed observed 90th percentile  True\n",
      "GFDL-CM4: min modeled value does not exceed observed 10th percentile  True\n",
      "GFDL-CM4: max modeled value does not exceed observed 90th percentile  True\n",
      "CanESM5: min modeled value does not exceed observed 10th percentile  True\n",
      "CanESM5: max modeled value does not exceed observed 90th percentile  True\n",
      "ACCESS-CM2: min modeled value does not exceed observed 10th percentile  True\n",
      "ACCESS-CM2: max modeled value does not exceed observed 90th percentile  True\n",
      "GFDL-CM4: min modeled value does not exceed observed 10th percentile  True\n",
      "GFDL-CM4: max modeled value does not exceed observed 90th percentile  True\n",
      "CanESM5: min modeled value does not exceed observed 10th percentile  False\n",
      "CanESM5: max modeled value does not exceed observed 90th percentile  True\n",
      "ACCESS-CM2: min modeled value does not exceed observed 10th percentile  False\n",
      "ACCESS-CM2: max modeled value does not exceed observed 90th percentile  True\n"
     ]
    }
   ],
   "source": [
    "for quarter in range(4):\n",
    "    obs_10 = np.percentile(quarters(hist_obs_tx, HIST_START, HIST_END)[quarter], 10)\n",
    "    obs_90 = np.percentile(quarters(hist_obs_tx, HIST_START, HIST_END)[quarter], 90)\n",
    "    for model in best_models_tx:\n",
    "        mod = quarters(hist_mods_tx[model] - 273.15, HIST_START, HIST_END)[quarter].flatten()\n",
    "        print('{0}: min modeled value does not exceed observed 10th percentile  {1}'.format(model, min(mod) <= obs_10))\n",
    "        print('{0}: max modeled value does not exceed observed 90th percentile  {1}'.format(model, max(mod) >= obs_90))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847140a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (halfdegenv)",
   "language": "python",
   "name": "halfdegenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
